import pandas as pd
df = pd.read_csv('/content/ICICIBANK.csv')
df
df = df[['Date','Prev Close',	'Open',	'High',	'Low',	'Last','Close',	'VWAP']]
df.to_csv('modified_dataset.csv', index=False)
df
import pandas as pd
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
print(df)
df = df[['Year',  'Month',  'Day', 'Prev Close',    'Open'  ,  'High' ,   'Low',   'Last'  , 'Close',    'VWAP']]
df.to_csv('modified_dataset.csv', index=False)
df
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)
X = df.drop(['Close'], axis=1)  # Only drop 'Close' since 'Date' is not present or not to be dropped.
y = df['Close']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

def evaluate_model(model_name, y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    print(f"{model_name} - MSE: {mse}, RMSE: {rmse}, R^2: {r2}")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled_reshaped = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))
X_train_cnn_lstm, X_test_cnn_lstm, y_train, y_test = train_test_split(X_scaled_reshaped, y, test_size=0.2, random_state=42)

models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor(),
    'SVR': SVR()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    evaluate_model(name, y_test, y_pred)

cnn_model = Sequential([
    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_cnn_lstm.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(50, activation='relu'),
    Dense(1)
])
cnn_model.compile(optimizer='adam', loss='mse')
cnn_model.fit(X_train_cnn_lstm, y_train, epochs=10, batch_size=32, verbose=0)
y_pred_cnn = cnn_model.predict(X_test_cnn_lstm).flatten()
evaluate_model('CNN', y_test, y_pred_cnn)


lstm_model = Sequential([
    LSTM(50, activation='relu', input_shape=(X_train_cnn_lstm.shape[1], 1)),
    Dense(1)
 ])
lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train_cnn_lstm, y_train, epochs=10, batch_size=32, verbose=0)
y_pred_lstm = lstm_model.predict(X_test_cnn_lstm).flatten()
evaluate_model('LSTM', y_test, y_pred_lstm)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import datetime as dt


df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])
df['Date_ordinal'] = df['Date'].map(dt.datetime.toordinal)

X = df[['Date_ordinal', 'Prev Close']]
targets = ['Open', 'High', 'Low', 'Last', 'Close', 'VWAP']


X_train, X_test, y_train, y_test = train_test_split(X, df[targets], test_size=0.2, random_state=42)


models = {target: LinearRegression().fit(X_train, y_train[target]) for target in targets}


example_date = "2024-02-15"  # Example date
example_prev_close = 1022.7  # Example previous close price


example_date_ordinal = dt.datetime.toordinal(pd.to_datetime(example_date))
example_input = [[example_date_ordinal, example_prev_close]]
predictions = {target: model.predict(example_input)[0] for target, model in models.items()}

for target, prediction in predictions.items():
    print(f"Predicted {target}: {prediction}")
